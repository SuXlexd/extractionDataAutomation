![Tu Empresa](assets/espot2.png)

# Web Scraping Project ğŸš€

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)

## ğŸ“– DescripciÃ³n

Este proyecto estÃ¡ diseÃ±ado para realizar **web scraping** en Mercado Libre, enfocado en la recolecciÃ³n de datos relacionados con el mercado de llantas en MÃ©xico. El proceso consta de dos etapas principales: la recolecciÃ³n de enlaces de interÃ©s y el consumo de dichos enlaces para almacenar informaciÃ³n relevante y capturas de pantalla.

---

## ğŸ› ï¸ CaracterÃ­sticas

- ğŸŒ **ExtracciÃ³n de datos estructurados**: ObtenciÃ³n de informaciÃ³n detallada sobre llantas de las principales marcas comerciales en MÃ©xico.
- ğŸ—‚ï¸ **Almacenamiento automatizado**: Los datos recolectados se almacenan en una base de datos estructurada. La definiciÃ³n de las tablas necesarias se encuentra en la carpeta `BDD`, y el archivo `.env` permite configurar el nombre de la base de datos.
- ğŸ“Š **HomologaciÃ³n de datos**: Proceso de normalizaciÃ³n de datos para corregir inconsistencias o clasificaciones errÃ³neas utilizando la herramienta de homologaciÃ³n proporcionada.
- ğŸ”„ **AutomatizaciÃ³n parcial**: Si bien el sistema aÃºn requiere intervenciÃ³n humana para iniciar los procesos de recolecciÃ³n y scraping, estÃ¡ diseÃ±ado para minimizar los esfuerzos manuales.

---

## ğŸš€ CÃ³mo comenzar

### Prerrequisitos

- Python 3.8 o superior.
- Dependencias enumeradas en el archivo `requirements.txt`.

### InstalaciÃ³n

1. Clona el repositorio:

   ```bash
   git clone https://github.com/espot-mkt/meli-distribuited-scrap.git
   cd meli-distribuited-scrap
   pip install -r requirements.txt
   ```

2. Configura tu base de datos local asegurÃ¡ndote de incluir las tablas necesarias. El cÃ³digo SQL para la creaciÃ³n de estas tablas se encuentra en la carpeta `BDD`.

3. Define las variables de entorno necesarias para la ejecuciÃ³n del proyecto, segÃºn lo especificado en el archivo `.env` .

## ğŸ§‘â€ğŸ’» Instrucciones de uso

### Etapa 1: RecolecciÃ³n de enlaces

Ejecuta el siguiente comando para iniciar la recolecciÃ³n de enlaces:
    
   ```bash
    python .\main COLLECT {LOCAL,QUIKERY}
```

Donde:

- `LOCAL`: Indica que la operaciÃ³n se realizarÃ¡ utilizando una base de datos local configurada previamente.
- `QUIKERY`: Utiliza una base de datos remota alojada en la BDD del dominio Quikery.

### Etapa 2: Proceso de scraping

Para extraer datos de los enlaces recolectados, utiliza el siguiente comando:

```bash
    python .\main.py SCRAP {LOCAL, QUIKERY}
```
